# Making Joint Inference in Meta-Analysis Practical

*An interactive app for heterogeneity-aware evidence synthesis*

---

## What is Meta-Analysis?

Meta-analysis combines results from multiple independent studies to produce a single, more precise estimate of a treatment effect. The key idea is simple: **weight each study by its precision**, giving more influence to studies with smaller uncertainty.

By pooling studies, meta-analysis:
- **Increases statistical power**‚Äîdetecting effects that individual studies miss
- **Improves precision**‚Äînarrower confidence intervals than any single study
- **Reconciles conflicting results**‚Äîproviding a unified summary
- **Provides evidence for decisions**‚Äîsupporting clinical guidelines and policy

Meta-analysis has become a cornerstone of evidence-based medicine, psychology, education, and many other fields. Since Gene Glass coined the term in 1976, the methodology has evolved significantly‚Äîyet some fundamental challenges remain.

---

## The Two Main Models: Fixed vs. Random Effects

When combining studies, we must choose how to model the underlying effects. The two dominant approaches reflect different assumptions about heterogeneity.

### Fixed-Effect Model

The fixed-effect model assumes **all studies share a single true effect** (Œ∏). Any observed variation is attributed solely to sampling error.

**Key assumption:** œÑ¬≤ = 0 (no heterogeneity)

**When to use:** Studies are sufficiently similar in populations, interventions, and settings. The goal is to estimate "the" common effect.

**Estimation:** Studies are weighted by precision (inverse variance):
```
Œ∏ÃÇ = Œ£(w·µ¢ √ó Y·µ¢) / Œ£w·µ¢,  where w·µ¢ = 1/œÉ·µ¢¬≤
```

### Random-Effects Model

The random-effects model allows **true effects to vary across studies**. Each study estimates its own true effect (Œ∏·µ¢), drawn from a distribution around the overall mean (Œº).

**Key assumption:** Œ∏·µ¢ ~ N(Œº, œÑ¬≤), where œÑ¬≤ is the between-study variance

**When to use:** Studies differ in populations, settings, or interventions. The goal is to estimate the *average* effect across a distribution of possible effects.

**Estimation:** Studies are weighted by total variance (within + between):
```
ŒºÃÇ = Œ£(w·µ¢* √ó Y·µ¢) / Œ£w·µ¢*,  where w·µ¢* = 1/(œÉ·µ¢¬≤ + œÑ¬≤)
```

The critical difference: **when œÑ¬≤ is large, all studies receive nearly equal weight**. The random-effects model produces wider confidence intervals that account for between-study variation.

---

## Why Heterogeneity Matters

Heterogeneity (œÑ¬≤) represents genuine variation in true effects across studies. It can arise from:

- **Clinical diversity**: Different participant characteristics, interventions, outcomes
- **Methodological diversity**: Variations in study design, quality, implementation
- **Unexplained factors**: Unknown sources of variation

### The Problem with Ignoring Heterogeneity

When heterogeneity exists but is ignored (using fixed-effect when œÑ¬≤ > 0), confidence intervals are **too narrow**‚Äîcreating false precision.

But even when using random-effects models, a critical problem remains:

> **Standard methods treat œÑ¬≤ as if it were known after estimating it.**

This "plug-in" approach:
1. Estimates œÑ¬≤ (using DerSimonian-Laird, REML, etc.)
2. Plugs that estimate into the confidence interval for Œº
3. **Ignores the uncertainty in œÑ¬≤ itself**

Research shows this can substantially underestimate uncertainty, especially when:
- The number of studies is small (k < 20)
- Heterogeneity is moderate to high (I¬≤ > 50%)

### Measuring Heterogeneity

Several statistics quantify heterogeneity:

**Cochran's Q**: Tests whether observed variation exceeds sampling error. A significant Q (p < 0.05) suggests heterogeneity exists.

**I¬≤**: The proportion of total variation due to heterogeneity (not sampling error):
- I¬≤ ‚âà 0%: No observed heterogeneity
- I¬≤ ‚âà 25%: Low heterogeneity
- I¬≤ ‚âà 50%: Moderate heterogeneity
- I¬≤ ‚âà 75%: High heterogeneity

**œÑ¬≤**: The actual between-study variance, on the scale of the effect measure.

But here's the catch: **knowing heterogeneity exists doesn't tell you what to do about it**.

---

## The Limitation of Explaining Heterogeneity

When heterogeneity is detected, the standard advice is to *explain* it through:
- **Subgroup analysis**: Stratify by categorical variables (e.g., age group, study quality)
- **Meta-regression**: Model effect size as a function of continuous moderators

But these approaches have limitations:

1. **Often inconclusive**: With few studies, statistical power is low
2. **Multiple testing concerns**: Testing many potential moderators inflates false positives
3. **Residual heterogeneity**: Even after adjustment, unexplained variation often remains
4. **Data requirements**: Need sufficient studies with moderator information

**What do practitioners do when heterogeneity remains unexplained?**

This is where the Joint Confidence Region approach offers a principled alternative.

---

## The JCR Approach: Joint Inference on (Œº, œÑ)

The Joint Confidence Region (JCR) method, introduced by Saad et al. (2019), performs **simultaneous inference on both Œº (the mean effect) and œÑ (the heterogeneity)**.

Instead of producing:
- One estimate of Œº
- One estimate of œÑ (treated as known)

JCR constructs a **two-dimensional confidence region** containing all (Œº, œÑ) pairs consistent with the data at a given confidence level.

### How It Works

The JCR is built using the likelihood-ratio test:

1. **Compute the likelihood** for each candidate (Œº, œÑ) pair on a dense grid
2. **Calculate the likelihood-ratio statistic**: T(Œº‚ÇÄ, œÑ‚ÇÄ) = -2 √ó log(L(Œº‚ÇÄ,œÑ‚ÇÄ) / L(ŒºÃÇ,œÑÃÇ))
3. **Compute p-values** using œá¬≤(df=2) reference distribution
4. **Form the region**: All points with p-value ‚â• Œ± comprise the (1-Œ±) confidence region

### What the JCR Reveals

The confidence region's **shape and size** tell you something important:

- **Large regions**: High uncertainty about both Œº and œÑ
- **Tilted regions**: Strong trade-off‚Äîplausible Œº values depend heavily on œÑ
- **Compact regions**: Robust inference‚Äîconclusions hold across plausible œÑ values

This geometric representation makes uncertainty **visible** in ways that one-dimensional intervals cannot.

---

## From Joint Inference to Practical Decisions

The JCR becomes especially powerful when translated into **questions practitioners actually care about**:

- What is the probability that a new study would show **any benefit**?
- How likely is the effect to exceed a **clinically meaningful threshold**?
- What's the chance of **harm** if we adopt this treatment?

### The Efficacy-Harm Probability Plot

Using the JCR, we can compute probability statements for any threshold of interest.

For a threshold T on the effect scale, the probability that a new study's true effect exceeds T is:
```
P(Œ∏_new ‚â• T) = 1 - Œ¶((T - Œº) / œÑ)
```

By projecting the JCR onto this probability function, we get **confidence bands** that honestly reflect uncertainty in both Œº and œÑ.

### The Probability Table: Actionable Numbers

The app generates tables like this:

| Threshold (RR) | P(effect ‚â§ threshold) | 95% CI |
|----------------|----------------------|--------|
| 0.50 | 45.2% | 18.3% ‚Äì 72.1% |
| 0.75 | 72.8% | 42.1% ‚Äì 93.5% |
| 1.00 (no effect) | 91.5% | 63.8% ‚Äì 99.0% |
| 1.25 | 97.2% | 78.4% ‚Äì 99.9% |

**What this tells practitioners:**
- "There's a 91.5% probability the treatment provides *some* benefit"
- "But we're only 63.8%‚Äì99.0% confident in that probability"
- "Even accounting for heterogeneity, harm is unlikely (< 9%)"

This probability framing connects statistical uncertainty to **clinical decision-making**.

---

## JCR Without Meta-Regression: Understanding Heterogeneity Anyway

Here's the key insight: **JCR helps you reason about heterogeneity even when you cannot explain it**.

Traditional workflow when heterogeneity exists:
1. Detect heterogeneity (high I¬≤)
2. Try to explain it (subgroup analysis, meta-regression)
3. Often fail to fully explain it
4. Report results with residual uncertainty unquantified

JCR workflow:
1. Detect heterogeneity
2. **Visualize the joint uncertainty** in (Œº, œÑ)
3. **Translate to decision thresholds** via probability plots
4. **Communicate honestly** about what the data support

The JCR contours show:
- Whether clinically important Œº values only occur under large œÑ
- Whether conclusions are robust across plausible heterogeneity levels
- The full range of (Œº, œÑ) pairs consistent with the data

**You don't need to explain heterogeneity to account for its uncertainty.**

---

## A Concrete Example: BCG Vaccine

The BCG vaccine meta-analysis (13 trials, tuberculosis prevention) is a classic example with massive heterogeneity (I¬≤ = 94%).

### Traditional Analysis
- Pooled RR = 0.48 (95% CI: 0.34‚Äì0.68)
- Conclusion: "BCG provides significant protection"

But this confidence interval **ignores uncertainty in œÑ¬≤**.

### JCR Analysis

The Joint Confidence Region shows a wide, tilted contour‚Äîindicating:
- High uncertainty about both Œº and œÑ
- Strong dependence: low Œº values are only plausible if œÑ is high

The probability table provides nuanced interpretation:

| Question | Probability | 95% CI |
|----------|-------------|--------|
| Any protection (RR < 1.0)? | 91.5% | 63.8% ‚Äì 99.0% |
| Strong protection (RR < 0.5)? | 47.3% | 22.1% ‚Äì 73.2% |
| Could be harmful (RR > 1.5)? | 1.8% | 0.1% ‚Äì 20.5% |

**Interpretation for practitioners:**
- Very likely BCG provides *some* protection
- But uncertain whether protection is strong or modest
- Harm is unlikely but not impossible
- The wide CIs honestly reflect heterogeneity uncertainty

This is richer than "RR = 0.48 (0.34‚Äì0.68)" alone.

---

## What the App Provides

This **open-source R/Shiny application** integrates JCR with classical meta-analysis tools.

### Core Analysis
- **Fixed-effect and random-effects models** (DL, REML, ML, Paule-Mandel)
- **Joint Confidence Regions** for (Œº, œÑ) at multiple confidence levels
- **Efficacy-harm probability plots** with confidence bands
- **Probability tables** for custom clinical thresholds

### Diagnostics
- **Deleted-residual Q-Q plots** (FE vs. RE comparison)
- **BLUP Q-Q plots** for random effects distribution
- 95% simulation-based confidence envelopes
- Formal normality tests

### Sensitivity Analysis
- **Leave-one-out JCR shifts**‚Äîsee how the region changes when each study is removed
- Funnel plots, Egger's test, trim-and-fill

### Data Support
- Binary outcomes (OR, RR)
- Continuous outcomes (SMD)
- Upload your data or use built-in examples
- Subgroup analysis and meta-regression

---

## When to Use the JCR Approach

The JCR is particularly valuable when:

| Situation | Why JCR Helps |
|-----------|---------------|
| **Few studies** (k < 20) | œÑ¬≤ estimation is most uncertain |
| **High heterogeneity** (I¬≤ > 40%) | Traditional CIs may be overconfident |
| **Threshold-based decisions** | Probability tables quantify chances of benefit/harm |
| **Unexplained heterogeneity** | Visualize implications without needing to explain it |
| **Conservative inference needed** | Avoid false precision |

When heterogeneity is low and k is large, traditional methods suffice‚Äîbut JCR still provides more transparent uncertainty accounting.

---

## Try It Yourself

**Live app (no installation required):**  
[https://davidgrab-meta-app.share.connect.posit.cloud/](https://davidgrab-meta-app.share.connect.posit.cloud/)

**Source code:**  
[https://github.com/davidgrab/meta-app](https://github.com/davidgrab/meta-app)

Built-in examples include:
- BCG vaccine (tuberculosis prevention)
- Beta-blockers (post-MI mortality)
- CBT for depression (continuous outcome)

---

## Get Involved

üî¨ **Use it** ‚Äî Try on your own data. Does the JCR reveal something the traditional analysis missed?

üêõ **Report issues** ‚Äî [Open an issue on GitHub](https://github.com/davidgrab/meta-app/issues)

üí° **Request features** ‚Äî Hazard ratios? Network meta-analysis? Let us know.

üìù **Share** ‚Äî If useful, cite Saad et al. (2019) and share with colleagues.

---

## Summary

Meta-analysis is not just about pooling numbers‚Äîit's about **quantifying uncertainty responsibly**.

Traditional methods work well when heterogeneity is low and studies are plentiful. But when heterogeneity is substantial and poorly estimated, they can create false precision.

The Joint Confidence Region provides a principled way to:
- **Acknowledge uncertainty** in both the mean effect and heterogeneity
- **Visualize the trade-offs** between Œº and œÑ
- **Translate uncertainty into probabilities** that support decisions
- **Communicate honestly** about what the data support

**You don't need to fully explain heterogeneity to account for its implications.** The JCR lets you reason about unexplained variation in a statistically principled way.

This app makes that approach practical.

---

## References

Saad, A., Yekutieli, D., Lev-Ran, S., Gross, R., & Guyatt, G.H. (2019). Getting more out of meta-analyses: A new approach to meta-analysis in light of unexplained heterogeneity. *Journal of Clinical Epidemiology*, 107, 101‚Äì106.

DerSimonian, R., & Laird, N. (1986). Meta-analysis in clinical trials. *Controlled Clinical Trials*, 7(3), 177‚Äì188.

Higgins, J.P.T., & Thompson, S.G. (2002). Quantifying heterogeneity in a meta-analysis. *Statistics in Medicine*, 21(11), 1539‚Äì1558.

Viechtbauer, W. (2005). Bias and efficiency of meta-analytic variance estimators in the random-effects model. *Journal of Educational and Behavioral Statistics*, 30(3), 261‚Äì293.

Borenstein, M., Hedges, L.V., Higgins, J.P.T., & Rothstein, H.R. (2021). *Introduction to Meta-Analysis* (2nd ed.). Wiley.

---

*This app was developed by David Grabois as part of a Master's thesis at Tel Aviv University, Department of Statistics and Operations Research, under the supervision of Prof. Daniel Yekutieli.*

*The thesis "Modern Meta-Analysis: Joint Confidence Regions for Effect Size and Heterogeneity" and full technical details are available in the [GitHub repository](https://github.com/davidgrab/meta-app).*
